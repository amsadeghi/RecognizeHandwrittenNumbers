{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##BigData Project\n",
        "#Building a Movie Recommendation System Using PySpark\n",
        "\n",
        "**Authors:**\n",
        "\n",
        "Amir Sadeghi,\n",
        "Behnam Yaghoubi\n",
        "\n",
        "**Supervisor:** Professor Marco Maggini\n"
      ],
      "metadata": {
        "id": "vqkjtAaIf9y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Objective:\n",
        "\n",
        "Develop a movie recommendation system.\n",
        "\n",
        "Utilize collaborative filtering with Alternating Least Squares (ALS).\n",
        "\n",
        "Implement hyperparameter tuning for model optimization."
      ],
      "metadata": {
        "id": "Zm8WY_vZhY4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Installing PySpark library\n",
        "\n",
        "Install PySpark to enable the development of the recommendation system.\n",
        "\n",
        "PySpark is a Python API for Spark."
      ],
      "metadata": {
        "id": "_PJBOaR6hrMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "6B9Kg2T_vWRT",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0594daed-f705-41fa-cdc9-1876f2c1e1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=156dfb217c9cca58c43f4d629f596a949ca39d50db11acefc84349e5511c478d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Importing the needed libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "4bowCnfjiF1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.sql.functions import explode"
      ],
      "metadata": {
        "id": "UzL4FH-VjE0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Initializing Spark Session\n",
        "\n",
        "The session is the entry point for DataFrame and SQL functionality."
      ],
      "metadata": {
        "id": "vVmvRI2qjPkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Movie Recommendation System\").getOrCreate()"
      ],
      "metadata": {
        "id": "3M7NJNMwjP-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Load ratings and movies datasets from CSV files.\n",
        "\n",
        "header=True indicates that the first row is a header.\n",
        "\n",
        "inferSchema=True automatically infers data types."
      ],
      "metadata": {
        "id": "fy1Nn59jjaiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = spark.read.csv(\"./ratings.csv\", header=True, inferSchema=True)\n",
        "movies = spark.read.csv(\"./movies.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "7n5KvpZrjZu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Data Caching and Cleaning\n",
        "\n",
        "Cache the data for better performance as they are accessed multiple times.\n",
        "\n",
        "Drop rows with null values to ensure data quality."
      ],
      "metadata": {
        "id": "QK-cjo9Cjuyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.cache()\n",
        "movies.cache()\n",
        "\n",
        "ratings = ratings.na.drop()\n",
        "movies = movies.na.drop()"
      ],
      "metadata": {
        "id": "vdK5E_CdjvK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Preparing Data for ALS\n",
        "Convert data types to integers for userId and movieId, and float for rating.\n",
        "\n",
        "ALS requires specific data types for processing.\n"
      ],
      "metadata": {
        "id": "Kds98XTmkn35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings.selectExpr(\"cast(userId as int) userId\",\n",
        "                             \"cast(movieId as int) movieId\",\n",
        "                             \"cast(rating as float) rating\")"
      ],
      "metadata": {
        "id": "hHJxj2-Ukocd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Splitting the Data\n",
        "Split the ratings data into training (80%) and test (20%) sets.\n",
        "\n",
        "A seed value ensures reproducibility."
      ],
      "metadata": {
        "id": "bcHLuw1ik_0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training, test) = ratings.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "OA2FbfbXlAOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Building and Training the ALS Model\n",
        "\n",
        "ALS (Alternating Least Squares) is a popular algorithm used in collaborative filtering for building recommendation systems. It is particularly well-suited for scenarios involving large datasets of user-item interactions, such as movie ratings, product purchases, or any situation where recommendations are made based on user behavior.\n",
        "\n",
        "###Collaborative Filtering:\n",
        "\n",
        "* ALS is a collaborative filtering technique, meaning it makes recommendations based on patterns of user-item interactions (e.g., which users rated which movies and how).\n",
        "It focuses on finding latent factors that explain observed user-item interactions.\n",
        "\n",
        "###Matrix Factorization:\n",
        "* The core idea behind ALS is to factorize a large user-item interaction matrix $R$ into two lower-dimensional matrices: $U$ (user factors) and $M$ (item factors).\n",
        "\n",
        " $R≈U⋅M^T, where: $\n",
        "\n",
        " * $R$ is the original user-item interaction matrix.\n",
        " * $U$ is the user-factor matrix (users x latent factors).\n",
        " * $M$ is the item-factor matrix (items x latent factors).\n",
        "\n",
        "###Alternating Optimization:\n",
        "\n",
        "* ALS iteratively optimizes one matrix while keeping the other fixed, alternating between the two until convergence.\n",
        "* First, it fixes the item matrix $M$ and solves for the user matrix $U$.\n",
        "* Then, it fixes the user matrix $U$ and solves for the item matrix $M$.\n",
        "* This process is repeated until the algorithm converges to a solution.\n",
        "\n",
        "###Loss Function:\n",
        "* ALS minimizes the regularized least squares error:\n",
        "\n",
        "  $∑_{(u,i)∈R}(R_{ui}−U_u⋅M_i)^2+λ(∥U∥^2+∥M∥^2)$\n",
        " * $(u,i)∈R$ are the observed user-item interactions.\n",
        " * $R_{u,i}$ is the observed rating of user $u$ for item $i$.\n",
        " * $U_u$ is the latent factor vector for user $u$.\n",
        " * $M_i$​ is the latent factor vector for item $i$.\n",
        " * $λ$ is a regularization parameter to prevent overfitting.\n",
        "\n",
        "Configure the ALS model with specified parameters.\n",
        "\n",
        "Train the model using the training dataset."
      ],
      "metadata": {
        "id": "KBc4Fg9blXRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "als = ALS(maxIter=5, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\", nonnegative=True)\n",
        "model = als.fit(training)"
      ],
      "metadata": {
        "id": "ZaHSqMgrlX2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Making Predictions\n",
        "\n",
        "Generate predictions on the test dataset. Before refining tuning on the full dataset serves the purpose of quickly assessing the initial performance of the ALS model. It's crucial for understanding the starting point of model effectiveness and provides a baseline for comparison with the refined model after hyperparameter tuning.\n",
        "\n",
        "Display the first five predictions."
      ],
      "metadata": {
        "id": "28mreocnljlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test)\n",
        "predictions.show(5)"
      ],
      "metadata": {
        "id": "FFoXIxH2lkC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0b75fd-6596-4dfd-9174-1e67ae09500a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating|prediction|\n",
            "+------+-------+------+----------+\n",
            "|   148|    356|   4.0| 3.7171543|\n",
            "|   148|   4896|   4.0| 3.5658805|\n",
            "|   148|   4993|   3.0|  3.719834|\n",
            "|   148|   7153|   3.0| 3.7453744|\n",
            "|   148|   8368|   4.0| 3.8152897|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Evaluating the Model\n",
        "\n",
        "Evaluate the model using RMSE (Root Mean Square Error).\n",
        "\n",
        "Lower RMSE indicates better model performance."
      ],
      "metadata": {
        "id": "HAULHySMl4za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse}\")"
      ],
      "metadata": {
        "id": "6jTsn2iBl5Im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4f9156-fa28-4e82-fb22-3db6b0f27349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 0.8797059001059495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Hyperparameter Tuning\n",
        "\n",
        "Build a parameter grid to search for optimal ALS hyperparameters.\n",
        "\n",
        "Use cross-validation for robust evaluation."
      ],
      "metadata": {
        "id": "YO-hdlG0mDau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(als.rank, [10, 50, 100]) \\\n",
        "    .addGrid(als.regParam, [0.01, 0.05, 0.1]) \\\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=als,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=5)"
      ],
      "metadata": {
        "id": "UCb6DPZRmDuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. Initial Tuning on a Smaller Sample\n",
        "\n",
        "Perform initial hyperparameter tuning on a smaller subset of the training data.\n",
        "\n",
        "Extract and display the best parameters."
      ],
      "metadata": {
        "id": "7rbcIxM9mPsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_training, _ = training.randomSplit([0.1, 0.9], seed=1234)\n",
        "initial_cvModel = crossval.fit(small_training)"
      ],
      "metadata": {
        "id": "2_yCdyr9mQSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. Refine Tuning on Full Dataset\n",
        "\n",
        "Conduct full hyperparameter tuning using the entire training dataset.\n",
        "\n",
        "Evaluate the refined model's performance on the test dataset."
      ],
      "metadata": {
        "id": "LdIAAgI6miT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cvModel = crossval.fit(training)\n",
        "bestModel = cvModel.bestModel\n",
        "predictions = bestModel.transform(test)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Best model's root-mean-square error = {rmse}\")"
      ],
      "metadata": {
        "id": "fno-fca1mg_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415b4a87-3b7d-4a45-ad7c-d74172381c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model's root-mean-square error = 0.8705656722581655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14. Generating Recommendations\n",
        "\n",
        "Generate top 10 movie recommendations for a specific user.\n",
        "\n",
        "Example shown for user_id = 123."
      ],
      "metadata": {
        "id": "hsj3uyUam1SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 123\n",
        "user_recs = bestModel.recommendForAllUsers(10)\n",
        "user_recs.filter(user_recs.userId == user_id).show()"
      ],
      "metadata": {
        "id": "oHBnhaxIm12E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b082829f-4b4a-4b4e-8361-6f0917c65007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|   123|[{171495, 4.80851...|\n",
            "+------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. Displaying Recommended Movie Titles\n",
        "\n",
        "Explode the recommendations column to get individual movie recommendations.\n",
        "\n",
        "Join with the movies dataset to display movie titles and ratings."
      ],
      "metadata": {
        "id": "OKbZIqD8nITH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_recs = user_recs.filter(user_recs.userId == user_id).select(\"recommendations\")\n",
        "user_recs = user_recs.withColumn(\"recommendation\", explode(\"recommendations\"))\n",
        "user_recs = user_recs.select(\"recommendation.*\")\n",
        "user_recs = user_recs.join(movies, on=\"movieId\")\n",
        "user_recs.select(\"movieId\", \"title\", \"rating\").show()\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "6-KgGGm1nIoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d42d02-4906-40a7-d3b0-388281f832c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------+\n",
            "|movieId|               title|  rating|\n",
            "+-------+--------------------+--------+\n",
            "| 171495|              Cosmos|4.808518|\n",
            "|  78836|Enter the Void (2...| 4.78131|\n",
            "| 184245|De platte jungle ...|4.739649|\n",
            "| 179135|Blue Planet II (2...|4.739649|\n",
            "| 138966|Nasu: Summer in A...|4.739649|\n",
            "| 117531|    Watermark (2014)|4.739649|\n",
            "|  86237|  Connections (1978)|4.739649|\n",
            "|  84273|Zeitgeist: Moving...|4.739649|\n",
            "|  74226|Dream of Light (a...|4.739649|\n",
            "|  26928|Summer's Tale, A ...|4.739649|\n",
            "+-------+--------------------+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}